{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IgwgEBuXX_ou"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "import inspect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    assert config.n_embd % config.n_head == 0\n",
        "    self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd) # matrix 3 times as large so it can be broken into QKV\n",
        "    self.c_proj = nn.Linear(config.n_embd, config.n_embd) # output projection\n",
        "    self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "    self.n_head = config.n_head\n",
        "    self.n_embd = config.n_embd\n",
        "    # mask to attend to only tokens occuring previously to the current token\n",
        "    # only needed for normal attention implementation\n",
        "    #self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size)).view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.size() # batch size, seqlen, embedding size\n",
        "    q, k, v = self.c_attn(x).split(self.n_embd, dim=2) # split into Q, K, V\n",
        "    k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "    q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "    v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "    # attention mechanism to create matrix (TxT) for all queries and keys\n",
        "    # att = (q @ k.transpose(-2, -1)) * 1.0/math.sqrt(k.size(-1)) # (B, nh, T, T) (normalized by hs = embd_size / nheads)\n",
        "    # att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf')) # (B, nh, T, T) (bias registered from before to be lower triangular)\n",
        "    # att = F.softmax(att, dim=-1) # softmax op\n",
        "    # y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "\n",
        "    # Flash Attention Implementation instead of above normal attention for speedup\n",
        "    y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # (B, nh, T, hs)\n",
        "    y = y.transpose(1, 2).contiguous().view(B, T, C) # concat all the head outputs together (B, T, C)\n",
        "    # out proj\n",
        "    y = self.c_proj(y)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "Wq4wN3u3ZJj1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd) # project to a higher space to be able to learn more features\n",
        "    self.gelu = nn.GELU(approximate=\"tanh\") # approximate w/ tanh b/c originally GELU calc in TF was slow\n",
        "    self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd) # project back to the embedding layer\n",
        "    self.c_proj.NANOGPT_SCALE_INIT = 1\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.c_fc(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.c_proj(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "FrULTq6FddAe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "      super().__init__()\n",
        "      self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "      self.attn = CausalSelfAttention(config)\n",
        "      self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "      self.mlp = MLP(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "      # have the x + in each step because of residual connections\n",
        "      x = x + self.attn(self.ln_1(x)) # attention (reduce where each token shares information)\n",
        "      x = x + self.mlp(self.ln_2(x)) # map (each token is individually processed)\n",
        "      return x"
      ],
      "metadata": {
        "id": "pU0vDgfxbwws"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024 # sequence length\n",
        "    vocab_size: int = 50257 # vocab size (num tokens)\n",
        "    n_layer: int = 12 # number of layers\n",
        "    n_head: int = 12 # number of heads\n",
        "    n_embd: int = 768 # embedding size"
      ],
      "metadata": {
        "id": "7XdHJyj7oT9Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd), # token embeddings\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd), # positional embeddings\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]), # for the hidden layers\n",
        "            ln_f = nn.LayerNorm(config.n_embd) # layer norm\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False) # output projection to the vocab size\n",
        "\n",
        "        # weight sharing scheme\n",
        "        self.transformer.wte.weight = self.lm_head.weight # weight tying\n",
        "\n",
        "        # applies the _init_weights function to all the sub modules of this module\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "      # weights according to the GPT2 implementation\n",
        "      if isinstance(module, nn.Linear):\n",
        "        std = 0.02\n",
        "        # layers in the MLP and CausalSelfAttention will have this attribute (as these layers contribute to\n",
        "        # the residual stream)\n",
        "        if hasattr(module, \"NANOGPT_SCALE_INIT\"):\n",
        "          if module.NANOGPT_SCALE_INIT:\n",
        "            # 2 times number of layers of residual streams because each block has MLP and Attention\n",
        "            # contributing to the residual stream\n",
        "            std *= (2 * self.config.n_layer)**-0.5\n",
        "        torch.nn.init.normal_(module.weight, mean=0.0, std=std) # weight normal dist with std .02\n",
        "        if module.bias is not None: # check if the layer has a bias term\n",
        "            torch.nn.init.zeros_(module.bias)\n",
        "      elif isinstance(module, nn.Embedding):\n",
        "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "      # idx is the token indices\n",
        "      B, T = idx.size()\n",
        "      # make sure prompt seqlen less than or equal to max model seq length\n",
        "      assert T <= self.config.block_size, f\"Cannot forward, index has length {T}, block size is {self.config.block_size}\"\n",
        "      pos = torch.arange(0, T, dtype=torch.long, device = idx.device) #shape (T) (makes sure input is on correct device)\n",
        "      pos_emb = self.transformer.wpe(pos) # shape (T, n_embd)\n",
        "      token_emb = self.transformer.wte(idx) # shape (B, T, n_embd)\n",
        "      x = token_emb + pos_emb # broadcasting done to be able to add these matrices\n",
        "\n",
        "      # forward the blocks of the transformers\n",
        "      for block in self.transformer.h:\n",
        "        x = block(x)\n",
        "\n",
        "      # layernorm and classifier\n",
        "      x = self.transformer.ln_f(x)\n",
        "      logits = self.lm_head(x)\n",
        "      loss = None\n",
        "\n",
        "      if targets is not None:\n",
        "        # need to flatten the matrices\n",
        "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "\n",
        "      return logits, loss\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, device):\n",
        "      # collect all the parameters and its tensors, and then filter for the ones\n",
        "      # that require gradients\n",
        "      param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "      param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "\n",
        "      # only parameters that have >= 2 dimensions need to be weight decayed\n",
        "      # weight decay is used for regularization and preventing overfitting similar to L2 Regularization\n",
        "      decay_params = [p for n, p in param_dict.items() if p.dim() >= 2] # >= 2 to make sure its only weights that are decayed and not bias\n",
        "      nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "      # create a list with the weights that need to be decayed and others that don't\n",
        "      optim_groups = [\n",
        "          {'params': decay_params, 'weight_decay': weight_decay},\n",
        "          {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "      ]\n",
        "\n",
        "      num_decay_params = sum(p.numel() for p in decay_params)\n",
        "      num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "      print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "      print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "\n",
        "      #Create AdamW optimizer and use the fused version if it is available\n",
        "      # kernel fusion to be more efficient instead of iterating over all the tensors\n",
        "      fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "      use_fused = fused_available and device == \"cuda\"\n",
        "      print(f\"using fused AdamW: {use_fused}\")\n",
        "      optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=(0.9, 0.95), eps=1e-8, fused=use_fused)\n",
        "      return optimizer\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
        "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "\n",
        "        # n_layer, n_head and n_embd are determined from model_type\n",
        "        config_args = {\n",
        "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
        "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "        }[model_type]\n",
        "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
        "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
        "        # create a from-scratch initialized minGPT model\n",
        "        config = GPTConfig(**config_args)\n",
        "        model = GPT(config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
        "\n",
        "        # init a huggingface/transformers model\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "\n",
        "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
        "        # this means that we have to transpose these weights when we import them\n",
        "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                # special treatment for the Conv1D weights we need to transpose\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                # vanilla copy over the other parameters\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "dRPdCcDoY550"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5eEfBssw_Id",
        "outputId": "9d1309f4-f1fc-462c-b4ea-9039a30b2047"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.2 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "with open(\"input.txt\", \"r\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "text = text[:1000]\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZcSeMvWlljn",
        "outputId": "6a53b8e2-b970-42c6-a140-c490707659e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-21 23:06:17--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-11-21 23:06:17 (26.2 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "class DataLoaderLite:\n",
        "  def __init__(self, B, T, process_rank, num_processes):\n",
        "    self.B = B\n",
        "    self.T = T\n",
        "    self.process_rank = process_rank\n",
        "    self.num_processes = num_processes\n",
        "\n",
        "    # at initialization load tokens from disc and store them into memory\n",
        "    with open(\"input.txt\", \"r\") as f:\n",
        "      text = f.read()\n",
        "\n",
        "    # encode the text into tokens\n",
        "    enc = tiktoken.get_encoding(\"gpt2\")\n",
        "    tokens = enc.encode(text)\n",
        "    self.tokens = torch.tensor(tokens)\n",
        "\n",
        "    print(f\"loaded {len(self.tokens)} tokens\")\n",
        "    print(f\"1 epoch = {len(self.tokens) // (self.B * self.T)} batches\")\n",
        "\n",
        "    # state\n",
        "    self.current_position = self.B * self.T * self.process_rank\n",
        "\n",
        "  def next_batch(self):\n",
        "    B, T = self.B, self.T\n",
        "    buf = self.tokens[self.current_position: self.current_position + B*T + 1]\n",
        "    # update current position\n",
        "    self.current_position += B*T * self.num_processes\n",
        "    # get the x and y\n",
        "    x = buf[:-1].view(B, T) # get everything but the last token\n",
        "    y = buf[1:].view(B, T) # get correct next tokens\n",
        "\n",
        "    # wrap back around if next batch results in OOB\n",
        "    if self.current_position + B*T*self.num_processes + 1 > len(self.tokens):\n",
        "      self.current_position = B*T * self.num_processes\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "poFcXmSls93o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install triton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoCzsrhX5yGk",
        "outputId": "d6c63d5a-d8a0-4263-e809-deee15e8479b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "Successfully installed triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import triton"
      ],
      "metadata": {
        "id": "D15Gf-PB6CbY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "from torch.distributed import init_process_group, destroy_process_group\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "import torch.distributed as dist\n",
        "\n",
        "# Launch the script with (torchrun --standalone --nproc_per_node=8 train_gpt2.py)\n",
        "\n",
        "# set up DDP (distributed data parallel)\n",
        "# use torchrun to set RANK, LOCAL_RANK, and WORLD_SIZE\n",
        "ddp = int(os.environ.get(\"RANK\", -1)) != -1\n",
        "if ddp:\n",
        "  assert torch.cuda.is_available(), \"DDP requires CUDA\"\n",
        "  init_process_group(backend=\"nccl\")\n",
        "  ddp_rank = int(os.environ[\"RANK\"])\n",
        "  ddp_local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
        "  ddp_world_size = int(os.environ[\"WORLD_SIZE\"])\n",
        "  device = f\"cuda:{ddp_local_rank}\"\n",
        "  torch.cuda.set_device(device)\n",
        "  master_process = ddp_rank == 0 # master process chose randomly to be 0 for logging etc\n",
        "else:\n",
        "  # single process run\n",
        "  master_process = True\n",
        "  ddp_rank = 0\n",
        "  ddp_local_rank = 0\n",
        "  ddp_world_size = 1\n",
        "  device = \"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(1337)\n",
        "\n",
        "total_batch_size = 524288 # ~.5M 2**19\n",
        "B = 8\n",
        "T = 1024\n",
        "assert total_batch_size % (B * T * ddp_world_size) == 0, \"make sure total_batch_size divisibel by B * T * ddp_world_size\"\n",
        "# allows simulation of larger batch sizes without the memory restrictions\n",
        "# will end up doing grad_accum_steps number of forward and backward passes for each step\n",
        "grad_accum_steps = total_batch_size // (B * T * ddp_world_size)\n",
        "\n",
        "# print once\n",
        "if master_process:\n",
        "  print(f\"total desired batch size {total_batch_size}\")\n",
        "  print(f\"gradient accumulation steps {grad_accum_steps}\")\n",
        "\n",
        "#print(\"I am DDP rank \", ddp_rank)\n",
        "#import sys; sys.exit(0)\n",
        "\n",
        "train_loader = DataLoaderLite(B=8, T=1024, process_rank=ddp_rank, num_processes=ddp_world_size)\n",
        "\n",
        "# TF32, will save some memory -- Not available on Tesla T4 GPU\n",
        "#torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "\n",
        "#model = GPT.from_pretrained('gpt2')\n",
        "model = GPT(GPTConfig(vocab_size=50304))\n",
        "model.to(device) # move tensors to device\n",
        "# compile model, take longer to compile but execution time sped up\n",
        "\"\"\"\n",
        "Compiles model to see what operations need to be run and can run the code\n",
        "efficiently. Implements kernel fusion to minimize the number of operations.\n",
        "\"\"\"\n",
        "model = torch.compile(model)\n",
        "\n",
        "if ddp:\n",
        "  model = DDP(model, device_ids=[ddp_local_rank])\n",
        "\n",
        "raw_model = model.module if ddp else model\n",
        "\n",
        "max_lr = 6e-4\n",
        "min_lr = max_lr * .1 # 10% of the max according to paper\n",
        "warmup_steps = 5\n",
        "max_steps = 50\n",
        "\n",
        "def get_lr(step):\n",
        "  # linear increase for warmup steps\n",
        "  if step < warmup_steps:\n",
        "    return max_lr * (step + 1) / warmup_steps\n",
        "  if step > max_steps:\n",
        "    return min_lr\n",
        "\n",
        "  # cosine decary to the min_lr\n",
        "  # value between 0 - 1 because normalizing the steps\n",
        "  decay_ratio = (step - warmup_steps) / (max_steps - warmup_steps)\n",
        "  assert 0 <= decay_ratio <= 1\n",
        "\n",
        "  coeff = 0.5 * (1 + math.cos(math.pi * decay_ratio))\n",
        "  return min_lr + coeff * (max_lr - min_lr)\n",
        "\n",
        "\n",
        "# create an optimizer for the loss\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), eps=1e-8)\n",
        "optimizer = raw_model.configure_optimizers(weight_decay=0.1, learning_rate=6e-4, device=device)\n",
        "\n",
        "# optimize loop\n",
        "for step in range(max_steps):\n",
        "  # get the next batch\n",
        "  t0 = time.time()\n",
        "\n",
        "\n",
        "  # always need to reset optimizer at the beginning\n",
        "  optimizer.zero_grad()\n",
        "  loss_accum = 0.0\n",
        "  for micro_step in range(grad_accum_steps):\n",
        "\n",
        "    x, y = train_loader.next_batch()\n",
        "    x = x.to(device) # move tensors from cpu to device\n",
        "    y = y.to(device)\n",
        "    # cast logits to be bfloat16 (going to change tensors)\n",
        "    #with torch.autocast(device_type=device, dtype=torch.bfloat16): (not supported on Tesla T4 GPU)\n",
        "    # calculate logits and the loss\n",
        "    logits, loss = model(x, y)\n",
        "    loss /= grad_accum_steps # normalize the loss\n",
        "    loss_accum += loss.detach()\n",
        "    # backwards step to calculate gradients (+=)\n",
        "    if ddp:\n",
        "      model.require_backward_grad_sync = (micro_step == grad_accum_steps - 1) # only do the sharing btwn processes on last iteration\n",
        "    loss.backward() # gradients will continue to add up b/c .backward() always does a +=\n",
        "\n",
        "    if ddp:\n",
        "      dist.all_reduce(loss_accum, op=dist.ReduceOp.AVG)\n",
        "\n",
        "  norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip gradients to prevent exploding gradients\n",
        "\n",
        "  lr = get_lr(step)\n",
        "  # optimizer might have more than one param other than lr\n",
        "  # iterate through the params and update the lr\n",
        "  for p in optimizer.param_groups:\n",
        "    p['lr'] = lr\n",
        "\n",
        "  # do the optimization\n",
        "  optimizer.step()\n",
        "\n",
        "  torch.cuda.synchronize() # needed b/c CPU schedules GPU kernels to run and then continues so acts as a block\n",
        "  t1 = time.time()\n",
        "  if master_process:\n",
        "    print(f\"step {step} loss {loss_accum.item():.6f} time {t1-t0} lr {lr:.4e} norm {norm:.4f}\")\n",
        "\n",
        "if ddp:\n",
        "  destroy_process_group()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuD1B0lslgZY",
        "outputId": "fb9ea44c-a581-43ac-d193-2564b613620b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total desired batch size 524288\n",
            "gradient accumulation steps 64\n",
            "loaded 338025 tokens\n",
            "1 epoch = 41 batches\n",
            "num decayed parameter tensors: 50, with 124,354,560 parameters\n",
            "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
            "using fused AdamW: True\n",
            "step 0 loss 10.938887 time 155.32537126541138 lr 1.2000e-04 norm 27.0152\n",
            "step 1 loss 9.593569 time 127.2419023513794 lr 2.4000e-04 norm 7.5646\n",
            "step 2 loss 9.076535 time 127.14698219299316 lr 3.6000e-04 norm 2.3658\n",
            "step 3 loss 9.117402 time 127.20558905601501 lr 4.8000e-04 norm 5.1234\n",
            "step 4 loss 8.451342 time 126.84460926055908 lr 6.0000e-04 norm 2.3033\n",
            "step 5 loss 8.005286 time 126.78626203536987 lr 6.0000e-04 norm 1.9718\n",
            "step 6 loss 7.592834 time 126.73928022384644 lr 5.9934e-04 norm 1.7762\n",
            "step 7 loss 7.237749 time 127.0109224319458 lr 5.9737e-04 norm 1.4863\n",
            "step 8 loss 6.896439 time 126.99690842628479 lr 5.9410e-04 norm 1.1192\n",
            "step 9 loss 6.655927 time 127.00219416618347 lr 5.8954e-04 norm 1.1407\n",
            "step 10 loss 6.499631 time 127.00564408302307 lr 5.8372e-04 norm 1.8061\n",
            "step 11 loss 6.357316 time 126.99663925170898 lr 5.7666e-04 norm 1.3009\n",
            "step 12 loss 6.310370 time 127.06050062179565 lr 5.6840e-04 norm 1.7647\n",
            "step 13 loss 6.237617 time 126.89415502548218 lr 5.5897e-04 norm 1.5044\n",
            "step 14 loss 6.198271 time 127.08766746520996 lr 5.4843e-04 norm 0.9454\n",
            "step 15 loss 6.183991 time 127.11401438713074 lr 5.3683e-04 norm 0.4695\n",
            "step 16 loss 6.199239 time 127.16998314857483 lr 5.2422e-04 norm 2.4069\n",
            "step 17 loss 6.194416 time 127.02255630493164 lr 5.1067e-04 norm 1.4619\n",
            "step 18 loss 6.154597 time 127.03921437263489 lr 4.9623e-04 norm 0.6874\n",
            "step 19 loss 6.135531 time 127.12328672409058 lr 4.8098e-04 norm 1.0731\n",
            "step 20 loss 6.115943 time 127.08294224739075 lr 4.6500e-04 norm 1.1003\n",
            "step 21 loss 6.069847 time 127.3113214969635 lr 4.4836e-04 norm 0.6331\n",
            "step 22 loss 6.063158 time 127.197340965271 lr 4.3114e-04 norm 0.5999\n",
            "step 23 loss 6.025049 time 127.36140179634094 lr 4.1343e-04 norm 0.7737\n",
            "step 24 loss 6.002160 time 127.23516488075256 lr 3.9532e-04 norm 0.6223\n",
            "step 25 loss 5.993635 time 127.39485907554626 lr 3.7689e-04 norm 0.4348\n",
            "step 26 loss 5.974072 time 127.18792748451233 lr 3.5822e-04 norm 0.5983\n",
            "step 27 loss 5.987362 time 127.43478155136108 lr 3.3942e-04 norm 0.6433\n",
            "step 28 loss 5.961510 time 127.40104341506958 lr 3.2058e-04 norm 0.3967\n",
            "step 29 loss 5.955380 time 127.50184559822083 lr 3.0178e-04 norm 0.4113\n",
            "step 30 loss 5.955552 time 127.46881127357483 lr 2.8311e-04 norm 0.4212\n",
            "step 31 loss 5.937327 time 127.6879050731659 lr 2.6468e-04 norm 0.3678\n",
            "step 32 loss 5.948648 time 127.64818835258484 lr 2.4657e-04 norm 0.3130\n",
            "step 33 loss 5.921139 time 127.61309814453125 lr 2.2886e-04 norm 0.3380\n",
            "step 34 loss 5.912148 time 127.60935068130493 lr 2.1164e-04 norm 0.2412\n",
            "step 35 loss 5.913970 time 127.65085291862488 lr 1.9500e-04 norm 0.1967\n",
            "step 36 loss 5.896150 time 127.56803011894226 lr 1.7902e-04 norm 0.2159\n",
            "step 37 loss 5.910755 time 127.52320289611816 lr 1.6377e-04 norm 0.2018\n",
            "step 38 loss 5.882634 time 127.79903769493103 lr 1.4933e-04 norm 0.2534\n",
            "step 39 loss 5.872900 time 127.6683897972107 lr 1.3578e-04 norm 0.2754\n",
            "step 40 loss 5.874935 time 127.60974669456482 lr 1.2317e-04 norm 0.3211\n",
            "step 41 loss 5.859771 time 127.55509352684021 lr 1.1157e-04 norm 0.4598\n",
            "step 42 loss 5.875088 time 127.69123554229736 lr 1.0103e-04 norm 0.4225\n",
            "step 43 loss 5.848135 time 127.67729187011719 lr 9.1604e-05 norm 0.2738\n",
            "step 44 loss 5.842469 time 127.80982327461243 lr 8.3343e-05 norm 0.2539\n",
            "step 45 loss 5.845802 time 127.84902215003967 lr 7.6283e-05 norm 0.2441\n",
            "step 46 loss 5.830500 time 127.69928693771362 lr 7.0459e-05 norm 0.2693\n",
            "step 47 loss 5.848092 time 127.74769711494446 lr 6.5900e-05 norm 0.2330\n",
            "step 48 loss 5.823961 time 127.6603946685791 lr 6.2628e-05 norm 0.2299\n",
            "step 49 loss 5.820882 time 127.69247555732727 lr 6.0658e-05 norm 0.1868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if master_process:\n",
        "    torch.save(model.state_dict(), \"gpt_trained_model.pth\")"
      ],
      "metadata": {
        "id": "X3Egst6XMPRC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, prompt, max_length=50):\n",
        "    # Tokenize the input prompt\n",
        "    enc = tiktoken.get_encoding(\"gpt2\")\n",
        "    input_ids = enc.encode(prompt)\n",
        "    input_ids = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Ensure the model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Move input to the correct device (GPU or CPU)\n",
        "    input_ids = input_ids.to(device)\n",
        "\n",
        "    # Start generating tokens\n",
        "    generated = input_ids\n",
        "    for _ in range(max_length):\n",
        "        # Forward pass to get logits\n",
        "        with torch.no_grad():\n",
        "            logits, _ = model(generated)\n",
        "\n",
        "        # Take the last token logits, convert to probabilities\n",
        "        logits = logits[:, -1, :]\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "        # Sample from the distribution (can use `torch.argmax` for greedy decoding)\n",
        "        next_token = torch.multinomial(probabilities, 1)\n",
        "\n",
        "        # Append the generated token to the input sequence\n",
        "        generated = torch.cat([generated, next_token], dim=1)\n",
        "\n",
        "    # Decode the generated tokens back into text\n",
        "    generated_text = enc.decode(generated[0].cpu().numpy())\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "prompt = \"Once upon a time\"\n",
        "generated_text = generate_text(model, prompt, max_length=100)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "KlGmAHYROEqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_path = \"/content/drive/My Drive/gpt_trained_model.pth\"  # Update path as needed\n",
        "if master_process:\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jZB9SSeZuv-",
        "outputId": "9bd824b1-00db-49c5-ebe9-e38f8210d1d5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Model saved to /content/drive/My Drive/gpt_trained_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxrSlxb2cMHo",
        "outputId": "58db5adf-38ef-4640-c45e-512d19a1f8df"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "# Define the evaluation loop for text generation\n",
        "def generate_text(model, enc, device, num_return_sequences=2, max_length=128, prompt=\"What hath you say,\"):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Encode the input prompt and prepare the input tensor\n",
        "    tokens = enc.encode(prompt)\n",
        "    tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "    tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)  # Repeat for num_return_sequences\n",
        "    xgen = tokens.to(device)  # Move to the appropriate device (GPU/CPU)\n",
        "\n",
        "    # Create a random generator for sampling\n",
        "    sample_rng = torch.Generator(device=device)\n",
        "    sample_rng.manual_seed(42)  # Set a seed for reproducibility\n",
        "\n",
        "    # Generate tokens until reaching max_length\n",
        "    while xgen.size(1) < max_length:\n",
        "        with torch.no_grad():  # No gradient tracking during generation\n",
        "            with torch.autocast(device_type=device, dtype=torch.bfloat16):  # Mixed precision (optional)\n",
        "                logits, _ = model(xgen)  # Get logits (B, T, vocab_size)\n",
        "\n",
        "            logits = logits[:, -1, :]  # Get logits for the last token (B, vocab_size)\n",
        "            probs = F.softmax(logits, dim=-1)  # Get probabilities for the next token\n",
        "\n",
        "            # Top-k sampling: Select the top 50 tokens\n",
        "            topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
        "\n",
        "            # Sample from the top-k probabilities\n",
        "            ix = torch.multinomial(topk_probs, 1, generator=sample_rng)  # (B, 1)\n",
        "            xcol = torch.gather(topk_indices, -1, ix)  # (B, 1)\n",
        "\n",
        "            # Append the sampled token to the sequence\n",
        "            xgen = torch.cat((xgen, xcol), dim=1)\n",
        "\n",
        "    # Decode and print the generated sequences\n",
        "    for i in range(num_return_sequences):\n",
        "        tokens = xgen[i, :max_length].tolist()  # Get the generated tokens for this sequence\n",
        "        decoded = enc.decode(tokens)  # Decode tokens back to text\n",
        "        print(f\"Generated text (sample {i}): {decoded}\")\n",
        "\n",
        "# Example usage\n",
        "# Assuming 'model' is your trained model and 'enc' is your tokenizer\n",
        "\n",
        "# Move model to device (if not already done)\n",
        "model.to(device)\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "# Generate text from the model\n",
        "generate_text(model, enc, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ELy3jq7REXd",
        "outputId": "a2d0602f-947d-4c2c-b4b0-939113f4b02d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text (sample 0): What hath you say,\n",
            "\n",
            "A, I you to?T that and her:\n",
            "If to, myUS the.\n",
            "\n",
            "That my, I thy on, for he you and:\n",
            "O a, to;And of,\n",
            "To my?\n",
            "And's,\n",
            "H,\n",
            "With with for and:\n",
            "In!\n",
            " sir, for I this with?\n",
            "H?\n",
            "As not beIO!\n",
            "Of in.\n",
            "\n",
            "\n",
            "And\n",
            "\n",
            "What with,\n",
            "R\n",
            "With with me shall, but\n",
            "Th?\n",
            " sir:\n",
            "R, is him\n",
            "To\n",
            "My of'd be,\n",
            "\n",
            "Generated text (sample 1): What hath you say, this your so you,\n",
            "The her, I he with! I thy the:\n",
            "KING:\n",
            "The,\n",
            "What, the:What.First\n",
            "If,\n",
            "Why that\n",
            "No that with:\n",
            "For me your.\n",
            "O is it it by I my:\n",
            "This\n",
            "\n",
            "That and it, be not,\n",
            "The's a,\n",
            "HowIO.Now, thisEN is for be\n",
            "Now.\n",
            "I the all of the;\n",
            "\n",
            "O;\n",
            " I's that.\n",
            "What.\n",
            " but have.\n",
            "\n",
            "For for with his shall'\n",
            "\n",
            " for he:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/My Drive\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLeQOGLac9xp",
        "outputId": "d68b1558-040e-4804-8ee0-6276d85f7e1b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['FABLES.docx.gdoc', 'Untitled document (101).gdoc', 'Adventure of Jason Chase.docx', 'Adventure of Jason Chase (1).docx.gdoc', 'Adventure of Jason Chase.docx.gdoc', 'Untitled document (100).gdoc', 'Untitled document (99).gdoc', 'social studies china project.gdoc', 'physical features.gdoc', 'IMG_2520.JPG', 'IMG_2520.JPG.gdoc', 'IMG_6856.JPG', 'tenderfoot pictures', 'Untitled document (98).gdoc', 'IMG_3642.JPG', 'IMG_3641.JPG', '2016-11-17-PHOTO-00000028.jpg', 'Quadratic_Equations.jpeg', 'Radicals.jpeg', 'passwords', 'LeadershipCardsrev20150607 (1).xlsx', 'LeadershipCardsrev20150607.xlsx', 'LeadershipCardsrev20150607.xlsx.gsheet', 'Untitled presentation (5).gslides', 'winmail.dat', 'IMG-5954.JPG', 'Ankith Bachhu Outsiders essay.gdoc', 'Outsiders essay.gdoc', 'Outsiders Essay.gdoc', 'Treachery (2).gdoc', 'Treachery (1).gdoc', 'Treachery.gdoc', 'Vocab words.gdoc', 'Untitled document (97).gdoc', 'Treachery Final Draft.gdoc', 'Untitled document (96).gdoc', 'Untitled presentation (4).gslides', 'How to descirbe our team.gdoc', 'FLL_questionnaire_sprinkler_system_with_answers.docx.gdoc', 'Item 6.gdoc', 'Core Values.gslides', 'Nowhere Fast.mp3', 'Core Values Consolidation.gdoc', 'S.A.S.S.gform', 'S.A.S.S (Responses).gsheet', 'CORE VALUES.gdoc', 'Compare Contrast.gdoc', 'Untitled document (95).gdoc', 'IMG-6133.JPG', 'IMG-6134.JPG', 'IMG-6135.JPG', 'IMG-6136.JPG', 'Star leadership sign offs.JPG', 'Untitled document (94).gdoc', 'Ankith - Skeletal System.gdoc', 'Rap 1.gdoc', 'Rap 1 completion.gdoc', 'RAP 2.gdoc', 'RAP 3.gdoc', 'EXAMPLE WEEKLY WAKE UP.gdoc', 'PE Report .gdoc', 'Surratt parke.gdoc', 'Untitled document (93).gdoc', 'Atzerodt.gdoc', 'Final.gdoc', 'History of Square dancing.gdoc', 'RAP 4 (1).gdoc', 'RAP 4.gdoc', 'Untitled document (92).gdoc', 'Friendly Letter.gdoc', 'Innocence of Surratt.gdoc', 'CLK argue essay.gdoc', 'Untitled document (91).gdoc', 'Trun letter.gdoc', 'Untitled document (90).gdoc', 'Sonnet.gdoc', 'Untitled document (89).gdoc', 'RAP 1 - 5.gdoc', 'WWU.gdoc', 'Untitled document (88).gdoc', 'Untitled presentation (3).gslides', 'First Aid.gslides', 'Mount Diablo Patrols and Cooking New Update.gdoc', 'January Debate.gdoc', 'January AFF.gdoc', 'February Debate.gdoc', 'Untitled document (87).gdoc', 'Chapter 8.pdf', 'Chapter 8.gdoc', 'Programming Concepts.gslides', 'brochure for bot esta.gdoc', 'Peeb 7 (1).gdoc', 'Peeb 7.gdoc', 'LOTF symbol.gdoc', 'Inspirational Speech.gdoc', 'IMG_20190414_012257.jpg', 'Sample words.gdoc', 'Note Creator.gslides', 'Society.gslides', 'Political Party.gdoc', 'jet (2).stl', 'Paper Towel Ec.gdoc', \"Interview Q's.gdoc\", 'ServiceHours.jpg', 'LifeRank.jpg', 'Leadershipcardp1.jpg', 'LeadershipCardp2.jpg', 'LeadershipCard.jpg', 'Untitled document (86).gdoc', 'Kuei Prez.gdoc', '\"Always on the side of the egg\" thesis.docx', 'Always on the side of the egg.gdoc', 'Wireless sensors.gdoc', 'DI Email.gdoc', 'Ankith-transcript.html', 'Screenshot_20190923-212207.jpg', 'Untitled presentation (2).gslides', 'Generations_Essay.docx', 'Generations_Essay.gdoc', 'Untitled document (85).gdoc', 'CookingMBMealPlanningSheetrev20181127.docx', 'Untitled document (84).gdoc', 'Copy of Flash Talk Self Evaluation.gdoc', 'Untitled document (83).gdoc', 'Untitled document (82).gdoc', 'Bachhu, Ankith - 3 - Logo Design Variations.png', 'Untitled document (81).gdoc', 'LeadershipCardsrev20150607 (1).gsheet', 'IMG-2777-Original.jpg', 'IMG-2737-Original.jpg', 'IMG-8042-Original.jpg', 'IMG-8039-Original.jpg', 'IMG-8038-Original.jpg', 'IMG-8037-Original.jpg', 'IMG-8036-Original.jpg', 'Copy of IMG-8036-Original.jpg', 'Copy of IMG-8042-Original.jpg', 'Untitled document (80).gdoc', 'Spiders.gdoc', 'Untitled document (79).gdoc', 'Turtle.ai', 'Ankith_Turtle.ai', 'Copy of Ankith_Turtle.ai', 'Untitled document (78).gdoc', 'Bachhu, Ankith - 3 - Vehicle Design.png', 'Untitled document (77).gdoc', 'Untitled presentation (1).gslides', 'Untitled document (76).gdoc', 'Kuei Final.gdoc', 'Armenia for Sharan.gdoc', 'Poster Info.gdoc', 'Rath Project.gdoc', 'Untitled document (75).gdoc', 'Untitled document (74).gdoc', 'Sea Levels.gdoc', 'SecondPic.psd', 'SecondPic (1).psd', 'Macro Econ Notes.gdoc', 'TronSuit.psd', 'Untitled document (73).gdoc', 'Ankith Bachhu 12.2 .gdoc', 'Ankith Physical Activity.gdoc', 'Untitled form.gform', 'Ankith Bachhu 12.3.gdoc', 'Untitled document (72).gdoc', 'Level1.jpg', 'Level2.jpg .jpg', 'Level3.jpg', 'Level_1.jpg', 'Level_2.jpg', 'Level_3.jpg', 'Ankith Bachhu 12.4.gdoc', 'food', 'Food Project.gdoc', 'Ankith Bachhu 12.5 Questions.gdoc', 'Poe.gdoc', 'Ed Gar Allen Poe.gdoc', 'Chapter 12 Essay Test.gdoc', 'Ankith Bachhu 13.1.gdoc', 'Colab Notebooks', 'WaterClips.mp4', 'hw1.jpg', 'hw2.jpg', 'Ankith Bachhu Silent Films.gdoc', 'Ankith Bachhu 13.2.gdoc', 'Document from Ankith Bachhu.pdf', 'Computer Security.pdf', 'Advanced Python.pdf', 'AllStats.pdf', 'DataAnalysis.pdf', 'DataMining.pdf', 'R Stats.pdf', 'Geographical Python.pdf', 'IMG_20200428_220824.jpg', 'IMG_20200428_220834.jpg', 'IMG_20200428_220912.jpg', 'Instagram Ads.gdoc', '13.4 Homework Assignment - Column chart 1.gsheet', 'Ankith Bachhu 13.4 Homework Assignment.gdoc', 'Untitled document (71).gdoc', 'Ankith Bachhu Chapter 13.3.gdoc', 'Ankith Bachhu Chapter 13.5 .gdoc', 'IMG_20200506_184755.jpg', 'hesslab.jpg', 'hesshw.jpg', 'realhesshw.jpg', 'Anikth Bachhu Chapter 13 Test.gdoc', 'Journal Response.gdoc', 'Untitled document (70).gdoc', 'LeadershipCardsrev20150607.gsheet', 'Chapter 14.2 Homework.gdoc', 'Chapter 14.3 .gdoc', 'Resume (7).gdoc', 'Business Cards.gdoc', '14.3 Questions.gdoc', 'Chapter 14.4.gdoc', 'IMG_20200528_104110.jpg', 'IMG_20200528_104216.jpg', 'IMG_20200528_104119.jpg', 'Globalization Rath Essay.gdoc', 'Rath Essay.gdoc', 'Chapter 14 test.gdoc', 'Untitled document (69).gdoc', 'Troop 153 Pictures.gslides', 'Bachhu, Ankith - 3 - Resume.gdoc', 'Classroom', 'Fremont Summer 2020 Bell Schedule.gdoc', 'SAT', 'Drone Parts.gdoc', 'gcc-arm-none-eabi-6-2017-q2-update-linux.tar.bz2', 'TC-04 TRP.pdf', 'IMG_20200723_204921.jpg', 'IMG_20200723_204835.jpg', 'Generations Essay.gdoc', 'VP08.pdf', 'IMG_20200730_201722.jpg', 'IMG_20200730_201731.jpg', 'TB13 (1).pdf', 'TB13.pdf', 'IMG_20200806_210355.jpg', 'IMG_20200806_210337.jpg', 'IMG_20200806_210348.jpg', 'Navio Build.gdoc', 'TWR_DRONE.gdoc', 'Untitled document (68).gdoc', 'Tevlin Notes.gdoc', 'AP Physics 1 Notes.gdoc', 'Untitled document (67).gdoc', 'AP Stats Notes.gdoc', 'Untitled document (66).gdoc', 'Untitled document (65).gdoc', 'Navio 2 Settings.gdoc', 'Citizenship in the Community.gslides', 'Dai Huck Mini Scripto.gdoc', 'Geschke Test.gdoc', 'Resume (6).gdoc', 'Untitled document (64).gdoc', 'Untitled document (63).gdoc', 'Resume (5).gdoc', 'Resume (4).gdoc', 'Untitled document (62).gdoc', 'Hope.gdoc', 'Home Depot Letter.gdoc', 'Project Phases.gdoc', 'Eagle Scout Project', 'Physics Explanation.gdoc', 'Merit Badge List.gdoc', 'Statement of Ambitions .gdoc', 'Dai Film Trailer.avi', 'Untitled document (61).gdoc', 'Quick ML Notes.gdoc', 'Stocks.gsheet', 'Untitled drawing.gdraw', 'Copy of Session 1 Handout - How to Explore and Collect Data.pdf', 'Copy of Session 4 Handout - Understanding Inference for Quantitative Data.pdf', 'Copy of Session 8 Handout - Top 10 Tips for Success on the AP Statistics Exam.pdf', 'Copy of Session 2 Handout - Simplifying Probability and Random Variables.pdf', 'Copy of Session 5 Handout - Essential Tools_Inference Flowchart, Formula Sheet, and Calculator.pdf', 'Copy of Session 7 Handout - Taming the Investigative Task on the AP Statistics Exam.pdf', 'Copy of Session 6 Handout - Rubrics for Free Response Success on the AP Statistics Exam.pdf', 'Copy of Session 3 Handout - Understanding Inference for Categorical Data.pdf', 'testingPDF.gdoc', 'Ankith Resume.gdoc', 'Untitled document (60).gdoc', 'Resume (3).gdoc', 'Untitled document (59).gdoc', 'Untitled presentation.gslides', 'Common App.gdoc', 'Mission Tutoring.gdoc', 'Resume (2).gdoc', 'Resume (1).gdoc', 'Untitled document (58).gdoc', 'Untitled document (57).gdoc', 'Untitled document (56).gdoc', 'Untitled document (55).gdoc', 'The College Panda SAT Writing, 2nd Edition by Nielson Phu (z-lib.org).pdf', 'Untitled document (54).gdoc', 'UC 1.gdoc', 'Untitled document (53).gdoc', 'College Notes (1).gdoc', 'Untitled document (52).gdoc', 'ASDRP.gdoc', 'common draft (1).gdoc', 'Untitled document (51).gdoc', 'Untitled document (50).gdoc', 'trash.gdoc', 'Untitled document (49).gdoc', 'Resume.gdoc', 'AP CS A Recommendation Letter form.gdoc', 'Untitled document (48).gdoc', 'UC 6.gdoc', 'College Notes.gdoc', 'Auto Editor.gdoc', 'Untitled document (47).gdoc', 'Chapter 1 C++ Homework.gdoc', 'Bulls Eye Lab Report.gdoc', 'BullsEye.pdf', 'BullsEye.gdoc', 'Bullseye Lab.gdoc', 'Ankith Bachhu Bullseye Lab.gdoc', 'common_draftoroni.gdoc', 'Untitled document (46).gdoc', 'UC-2 drafto.gdoc', 'They Say I Say Notes.gdoc', 'Coffee Filter Lab.gdoc', 'Ch 2 C++ Homework.gdoc', 'ERWC Thesis.gdoc', 'common draft.gdoc', 'Ch3 C++ Hw.gdoc', 'UC 1 Rought Draft.gdoc', 'Common App Draft.gdoc', 'Ch4 C++ Hw.gdoc', 'NHS essay.gdoc', 'Untitled document (45).gdoc', 'Comparison of Ankith B - UIUC-2 & C++ Chapter 5.gdoc', 'CHANDEEP SMITH.gdoc', 'common draftaroni .gdoc', 'C++ Chapter 5.gdoc', 'Untitled document (44).gdoc', 'UT Austin Personal Statement.gdoc', 'Ch 6 C++ Homework.gdoc', 'Untitled document (43).gdoc', 'UC essays.gdoc', 'Untitled document (42).gdoc', 'Untitled document (41).gdoc', 'NHS Personal Essay.gdoc', 'Chapter_7_Homework_C.docx', 'C++ Chapter 7 - Line chart 1.gsheet', 'C++ Chapter 7.gdoc', 'Untitled document (40).gdoc', 'Ch 8 C++ hw.gdoc', 'Internship.gdoc', 'Flowchart Intern.gdoc', 'Penn Interview Questions.gdoc', 'Revw 1.docx', 'Sample Questions for Exam 1.docx', 'Fashion Rules.gdoc', '2022-InspirASIAN-Scholarship-Application.docx', 'Untitled document (39).gdoc', 'My Dream.gdoc', 'Fashion Questions.gdoc', 'Ethos Logos Pathos.gdoc', 'Untitled document (38).gdoc', 'lab2.cpp', 'Untitled spreadsheet (2).gsheet', 'Internship Next Steps.gdoc', 'Untitled document (37).gdoc', 'DISC MATH CH 3 HW.gdoc', 'Untitled spreadsheet (1).gsheet', 'Output Format.gsheet', 'Untitled document (36).gdoc', 'Disc Math Ch 4 Hw.gdoc', 'College Weightages.gsheet', 'Chapter 5 Disc Math Hw.gdoc', 'USC Appeal Personal Copy.gdoc', 'Bachhu, Ankith', '2017-Fall-Citizenship_in_World.gsheet', 'Untitled document (35).gdoc', 'Questions.gdoc', 'Untitled document (34).gdoc', 'UMD VS Wisconsin.gdoc', 'Untitled document (33).gdoc', 'UMD and UWisc Visit details.gdoc', 'Maryland Trip.gsheet', 'Top Styles.gdoc', 'UMD and UCSC Price Breakdown.gsheet', 'IMG_20220419_120330.jpg', 'IMG_20220419_120322.jpg', 'College Ranking Factors.gsheet', 'Copy of Central Park 5.gdoc', 'Stats Review Guide.gdoc', 'STEAM PROJECT IDEAS.gdoc', 'baby.jpg', '280928092_526420818971256_7976681343416369465_n.gif', 'Disc Math Ch 7 Hw.gdoc', 'Copy of Undergraduate Action Plan.gdoc', 'DISC MATH CH 2 HW.gdoc', 'Chapter 6 Disc Math HW.gdoc', 'Clothing Rules.gdoc', 'Frank Musgrave - AP Microeconomics_Macroeconomics with 4 Practice Tests (2021, Barrons Educational Series) - libgen.li.pdf', 'Gayle Laakmann McDowell - Cracking the Coding Interview_ 189 Programming Questions and Solutions (2015, CareerCup) - libgen.lc.pdf', 'Deposit and Spending.gsheet', 'Untitled document (32).gdoc', 'Ankith_Pic.png', 'IMG_20210415_201224~2.jpg', 'Github Personal Token.gdoc', 'Michael T. Goodrich, Roberto Tamassia, Michael H. Goldwasser - Data Structures and Algorithms in Java, 6th Edition_ International Student Version (2014, Wiley) - libgen (1).lc.pdf', 'Michael T. Goodrich, Roberto Tamassia, Michael H. Goldwasser - Data Structures and Algorithms in Java, 6th Edition_ International Student Version (2014, Wiley) - libgen.lc.pdf', 'Robert Ellis, Denny Gulick - Student Solutions Manual to Accompany Calculus (2004, Thomson) - libgen.lc.pdf', 'Denny Gulick, Robert Ellis - Calculus With Concepts in Calculus Sixth(2006, Cengage Learning) - libgen.lc.pdf', 'mlvm.key.TXT', 'UMD Course Plan.gsheet', 'UMD Things to Buy Still.gdoc', 'Maryland Itinerary.gdoc', 'CS 131 review notes.gdoc', 'Untitled document (31).gdoc', 'Web of Lies essay - Ankith Bachhu.gdoc', 'Copy of UMD Course Plan for Stats Major.gsheet', 'Ankith Resume.pdf', 'Netflix Show Analysis.gdoc', 'Netflix Show Analysis.pdf', 'CMSC 132 Exam 1 Notes.gdoc', 'Week 6 Questions ENES210.gdoc', 'Persuasive Topic Proposal.gdoc', 'Informative Self Reflection.gdoc', 'Untitled document (30).gdoc', 'CS Major and Stats Major.gsheet', 'English Discussion.gdoc', 'Untitled document (29).gdoc', 'Copy of Persuasive Outline (1).gdoc', 'Copy of Persuasive Outline.gdoc', 'English Topic Proposal.gdoc', 'English 101 Inquiry Notes.gdoc', 'Annotated Bibliography.gdoc', 'Persuasive Outline.gdoc', 'Untitled document (28).gdoc', 'Copy of UMD Course Plan.gsheet', 'Untitled document (27).gdoc', 'Untitled document (26).gdoc', 'Business Analytics & Stats Minor With CS Major - Data Science Track.gsheet', 'Group Presentation My Part.gdoc', 'Position Paper.gdoc', 'Special Occassion Speech.gdoc', 'Untitled document (25).gdoc', 'College Payments.gsheet', 'Investing Ladder for TBills.gdoc', 'Florida Things to Do.gdoc', 'Copy of Business Analytics & Stats Minor With CS Major - Data Science Track - NEW PLAN - WORKING.gsheet', 'CMSC216.pdf', \"(Maryland) University of Maryland Academic Writing Program - Fearless Writing_ Rhetoric, Inquiry, Argument-Bedford _St.Martin's Macmillan Learning (2020) (1).pdf\", 'Untitled document (24).gdoc', 'CMSC 216 Loading shi.gdoc', 'Treasury Bills.gsheet', 'Untitled document (23).gdoc', 'Untitled document (22).gdoc', 'Untitled document (21).gdoc', 'Untitled document (20).gdoc', 'Untitled document (19).gdoc', 'Ankith Bachhu College Resume.gdoc', 'Copy of Ankith Bachhu College Resume.gdoc', 'Open AI Secret Key.gdoc', 'Untitled document (18).gdoc', 'Untitled document (17).gdoc', 'Aws Creds Element.gdoc', 'rajiv.tar.gz', 'Creating A De-Identification Profile.gdoc', 'Untitled document (16).gdoc', 'CMSC216 HW6.gdoc', 'Ankith Bachhu Cover Letter.gdoc', 'Element Github Token.gdoc', 'Copy of Dai Film Trailer.avi', 'AWS Associate Notes.gdoc', 'Dads Bday Speech.gdoc', 'Ankith Bachhu College Resume.docx', 'Untitled document (15).gdoc', 'Copy of Ankith Bachhu College Resume.docx', 'Untitled document (14).gdoc', 'Untitled document (13).gdoc', 'CapTech Values.gdoc', 'Untitled document (12).gdoc', 'MUSC204 Notes.gdoc', 'Untitled document (11).gdoc', 'Untitled document (10).gdoc', 'Untitled document (9).gdoc', 'Moneyball Opinion.gdoc', 'Humana.gdoc', \"Ankith's Investing.gsheet\", 'Untitled document (8).gdoc', 'Untitled document (7).gdoc', 'Untitled document (6).gdoc', 'Working Edit of Ankith Bachhu College Resume.docx', 'Copy of Working Edit of Ankith Bachhu College Resume.docx', 'Direct_Deposit_Form-Fillable (2).pdf', '2023 MD-Out of State (3).pdf', '2023_W-4 Federal (3).pdf', 'Untitled document (5).gdoc', 'plan a BSMS.gsheet', 'Untitled document (4).gdoc', 'Untitled document (3).gdoc', 'Untitled document (2).gdoc', 'ENGL 393 Resume Assignment.gdoc', 'Untitled document (1).gdoc', '2024+L4_L5+US+and+Canada+Corporate+Intern+Policy.pdf', 'Ankith-Bachhu-Resume-Updated.pdf', 'Untitled document.gdoc', 'WaterBudget_CISESS23_AnkithBachhu_v8 1 (1).gdoc', 'WaterBudget_CISESS23_AnkithBachhu_v8 1.gdoc', 'UC Essays.gdoc', 'bleh.gdoc', 'Pio.pdf', 'Pio-pages.pdf', 'Pio-upd.pdf', 'Passport.pdf', '000055_001.pdf', 'Project1 Data CMSC416.gdoc', 'Stat430CW2.gdoc', 'Stat430 Hw1.gdoc', 'Stat430 CW7.gdoc', 'Untitled spreadsheet.gsheet', 'Stat430CW9.gdoc', 'sample.gdoc', 'gpt_trained_model.pth']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Inference\n",
        "# num_return_sequences = 5\n",
        "# max_length = 30\n",
        "\n",
        "# device = \"cpu\"\n",
        "# if torch.cuda.is_available():\n",
        "#   device = \"cuda\"\n",
        "\n",
        "# #model = GPT.from_pretrained('gpt2')\n",
        "# model = GPT(GPTConfig())\n",
        "# model.eval() # evaluation mode means not going to use any backtracking so it won't cache values\n",
        "# model.to(device) # move tensors to GPU\n",
        "\n",
        "# import tiktoken\n",
        "# enc = tiktoken.get_encoding(\"gpt2\") # gpt2 token encoding\n",
        "# tokens = enc.encode(\"Hello, I'm a language model,\")\n",
        "# tokens = torch.tensor(tokens, dtype=torch.long) # (8, )\n",
        "# tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1) # (5, 8)\n",
        "# x = tokens.to(device) # X is the idx that can be passed into forward to obtain logits\n",
        "\n",
        "# torch.manual_seed(42)\n",
        "# torch.cuda.manual_seed(42)\n",
        "\n",
        "# while x.size(1) < max_length:\n",
        "#   # x is (B, T) w/ B = 5, T = 8\n",
        "#   with torch.no_grad():\n",
        "#     # logits of the next token\n",
        "#     logits = model(x) # (B, T, vocab_size)\n",
        "\n",
        "#     # get logits for the last position because thats the token that needs to be identified\n",
        "#     logits = logits[:, -1, :] # (B, vocab_size)\n",
        "\n",
        "#     # get the probabilites (use softmax)\n",
        "#     probs = F.softmax(logits, dim=-1) # (B, vocab_size)\n",
        "\n",
        "#     # topk = 50 (hf default)\n",
        "#     topk_probs, topk_indices = torch.topk(probs, k=50, dim=-1) # (B, 50)\n",
        "\n",
        "#     # select a token form topk_probs\n",
        "#     ix = torch.multinomial(topk_probs, 1) #(B, 1) (randomly select one from top 50)\n",
        "\n",
        "#     # gather corresponding indices\n",
        "#     xcol = torch.gather(topk_indices, -1, ix) # (B, 1) pick the ix token from top 50\n",
        "\n",
        "#     # append to the seq\n",
        "#     x = torch.cat((x, xcol), dim=1) # (B, T+1)  (add new token to the existing seq autoregressive)\n",
        "\n",
        "# for i in range(num_return_sequences):\n",
        "#   tokens = x[i,:max_length].tolist() # get the tokens up to max_length for the batch idx\n",
        "#   decoded = enc.decode(tokens)\n",
        "#   print(\">\", decoded)"
      ],
      "metadata": {
        "id": "aEUXFfcZZHYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Need to change it to raw_model after the DDP wrapper\n",
        "# let me think about how to be the."
      ],
      "metadata": {
        "id": "KexQxNMfrqTF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}